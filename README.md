# BYOD Synthetic Data Generator

Generate privacy-safe synthetic data that preserves the statistical properties of your original data without exposing sensitive information.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11 or higher
- 4GB RAM minimum
- 1GB free disk space

### Installation & Setup

1. **Clone the repository**
```bash
git clone https://github.com/your-org/Create-mockData-from-real-file.git
cd Create-mockData-from-real-file
```

2. **Create and activate virtual environment**
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**
```bash
cp .env.example .env
# Edit .env to add your Azure OpenAI credentials (optional)
```

5. **Start the application**
```bash
python main.py
```

The application will start at `http://localhost:8201`

### Verify Installation

Check the server status:
```bash
curl http://localhost:8201/health
```

You should see:
```json
{
  "status": "healthy",
  "openai_configured": false,
  "cache_enabled": true,
  "environment": "local"
}
```

## ğŸ“Š Features

### âœ… Production Ready
- **Privacy-First**: LLM never sees actual data values, only statistical metadata
- **Multiple Formats**: Supports CSV, JSON, Excel, Parquet, TSV
- **Web Interface**: User-friendly drag-and-drop interface with About page
- **Multi-File Generation**: Generate 1-20 files at once with ZIP download
- **REST API**: Programmatic access for automation
- **Local-First**: Works without cloud services

### ğŸš§ In Development
- **Statistical Preservation**: Basic distributions maintained (advanced correlations coming)
- **Intelligent Caching**: Metadata hashing implemented (vector similarity pending)
- **Clinical Data Support**: Domain-specific value generation planned
- **Data Dictionary Upload**: Constraint validation feature planned

## ğŸ–¥ï¸ Using the Web Interface

1. Open your browser to `http://localhost:8201`
2. Drag and drop your data file (CSV, JSON, Excel, etc.)
3. Adjust generation settings:
   - **Number of rows**: How many synthetic records to generate
   - **Match strictness**: How closely to match statistical properties (70-85% recommended)
   - **Number of files**: Generate 1-20 synthetic files at once
4. Click "Generate Synthetic Data"
5. Download your synthetic dataset (single file or ZIP for multiple)

## ğŸ”Œ API Usage

### Generate synthetic data via API

```bash
# Single file generation
curl -X POST "http://localhost:8201/generate" \
  -F "file=@your_data.csv" \
  -F "num_rows=1000" \
  -F "match_threshold=0.8" \
  -F "output_format=csv" \
  --output synthetic_data.csv

# Multiple file generation (returns ZIP)
curl -X POST "http://localhost:8201/generate" \
  -F "file=@your_data.csv" \
  -F "file_count=5" \
  -F "output_format=csv" \
  --output synthetic_data.zip
```

### Extract metadata only

```bash
curl -X POST "http://localhost:8201/metadata" \
  -F "file=@your_data.csv" \
  -o metadata.json
```

### API Documentation

View interactive API docs at: `http://localhost:8201/docs`

## ğŸ¯ Common Use Cases

### 1. Remove PHI from Medical Data
```python
# Upload medical records with patient information
# Get back statistically similar data without any real patient details
```

### 2. Create Test Data for Development
```python
# Upload small production sample
# Generate large test dataset maintaining relationships and patterns
```

### 3. Share Data Safely
```python
# Upload sensitive financial data
# Generate shareable synthetic version for vendors or partners
```

## âš™ï¸ Configuration

### Environment Variables

Key settings in `.env`:

```env
# Azure OpenAI (optional - enables LLM generation)
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-key-here

# Application Settings
LOG_LEVEL=INFO
APP_PORT=8201

# Local Storage
USE_LOCAL_STORAGE=true
LOCAL_STORAGE_PATH=./data/local_storage
LOCAL_CACHE_PATH=./data/cache
```

### Running on Different Port

```bash
# Edit .env file
APP_PORT=8202

# Or override when running
APP_PORT=8080 python main.py
```

## ğŸ“ Project Structure

```
Create-mockData-from-real-file/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/           # Core modules (data loader, metadata, generation)
â”‚   â”œâ”€â”€ api/            # API endpoints
â”‚   â”œâ”€â”€ web/            # Web interface (HTML/JS/CSS)
â”‚   â””â”€â”€ utils/          # Utilities (config, logging)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ samples/        # Sample data files
â”‚   â”œâ”€â”€ cache/          # Cached generation scripts
â”‚   â””â”€â”€ local_storage/  # Temporary storage
â”œâ”€â”€ tests/              # Unit tests
â”œâ”€â”€ infrastructure/     # IaC scripts (Terraform/Bicep)
â”œâ”€â”€ docs/               # Documentation
â”œâ”€â”€ main.py             # Application entry point
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ .env.example        # Environment variables template
```

## ğŸ§ª Testing

Run unit tests:
```bash
pytest tests/
```

Test with sample data:
```bash
# Sales data example
curl -X POST "http://localhost:8201/generate" \
  -F "file=@data/samples/sales_data.csv" \
  -F "match_threshold=0.85" \
  --output test_output.csv
```

## ğŸš¢ Deployment

### Docker Deployment
```bash
docker build -t byod-synthetic:latest .
docker run -p 8201:8201 --env-file .env byod-synthetic:latest
```

### Azure Deployment
```bash
cd infrastructure/terraform
terraform init
terraform apply
```

See [docs/DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md) for detailed instructions.

## ğŸ“š Documentation

- [Architecture Overview](docs/architecture-diagram.md) - System design and data flow
- [Developer Task List](developer_tasklist.md) - Active development tasks
- [Completed Tasks](archived/developer_tasklist_ARCHIVED.md) - Finished work archive
- [About Page](http://localhost:8201/about) - Interactive architecture diagram and FAQ

## âš ï¸ Known Limitations

- **Date Detection**: Some date formats (e.g., 2024-01-10) may not be automatically detected
- **Domain Knowledge**: Columns like "medication" get random values, not real drug names
- **Large Files**: Memory-based processing (streaming support planned)
- **Complex Relationships**: Multi-column correlations not fully preserved yet

## ğŸ› ï¸ Troubleshooting

### Port already in use
```bash
# Kill process on port 8201
kill -9 $(lsof -t -i:8201)
```

### Import errors
```bash
# Reinstall dependencies
pip install --upgrade -r requirements.txt
```

### No OpenAI credentials
The system works without Azure OpenAI using template-based generation. For enhanced AI generation, add credentials to `.env`.

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is proprietary and confidential.

## ğŸ†˜ Support

- Check the [documentation](docs/)
- Submit issues on GitHub
- Contact the development team

## ğŸ” Status Endpoints

- **Health Check**: `http://localhost:8201/health`
- **API Info**: `http://localhost:8201/api`
- **Interactive Docs**: `http://localhost:8201/docs`
- **Web Interface**: `http://localhost:8201`

## ğŸ—ï¸ Current Development Status

### Recently Completed (September 2025)
- âœ… Multi-file generation with ZIP download
- âœ… About page with architecture documentation
- âœ… Privacy documentation and FAQ

### Active Development
- ğŸ”§ Fixing date type detection for medical data
- ğŸ”§ Adding clinical reference data library
- ğŸ”§ Implementing data dictionary validation
- ğŸ”§ Enhancing LLM column understanding

See [developer_tasklist.md](developer_tasklist.md) for detailed development plans.

---

**Privacy Note**: Your uploaded file is processed in memory only and never saved to disk. Only statistical metadata (no actual values) is sent to the LLM for code generation, making it safe for PHI, PII, and other confidential information.
